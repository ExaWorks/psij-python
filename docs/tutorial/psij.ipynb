{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSI/J-Python Getting Started Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/psij_overview.png\" width=\"350\"/>\n",
    "\n",
    "PSI/J (Portable Submission Interface for Jobs), is an abstraction layer over cluster job schedulers. It allows your application to be written in a way that is (mostly) independent of the cluster(s) where it runs. It is a language agnostic specification. PSI/J-Python is a Python implementation of PSI/J.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install git+https://github.com/ExaWorks/psij-python.git >/dev/null 2>&1\n",
    "%pip show psij-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview \n",
    "\n",
    "When running a job, there are a number of things to specify:\n",
    "- What is to be run, such as executable, arguments, environment, etc. ([JobSpec](https://exaworks.org/psij-python/#docs/.generated/psij.html/#psij.job_spec.JobSpec))\n",
    "- What resources are needed by the job, such as the number of nodes ([ResourceSpec](https://exaworks.org/psij-python/#docs/.generated/psij.html/#psij.resource_spec.ResourceSpecV1))\n",
    "- Various miscellaneous properties, such as the queue to submit the job to ([JobAttributes](https://exaworks.org/psij-python/#docs/.generated/psij.html/#psij.job_attributes.JobAttributes))\n",
    "- The mechanism through which to run the job, such as local/exec, SLURM, PBS, etc. ([JobExecutor](https://exaworks.org/psij-python/#docs/.generated/psij.html/#psij.job_executor.JobExecutor))\n",
    "\n",
    "We also need an object to keep track of all this information, as well as the state of the execution. This object is an instance of a [Job](https://exaworks.org/psij-python/#docs/.generated/psij.html/#psij.job.Job)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Before we start, let us create a separate directory so that we don't overwrite each others' files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tempfile import mkdtemp\n",
    "\n",
    "os.makedirs('/tutorials/userdirs', exist_ok=True)\n",
    "workdir = mkdtemp(prefix='userdir-', dir='/tutorials/userdirs')\n",
    "os.chdir(workdir)\n",
    "print(workdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Usage\n",
    "Without further ado, let's create a simple job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from psij import Job, JobSpec\n",
    "\n",
    "job = Job(JobSpec(executable='/bin/date', stdout_path=Path('the-date.txt')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easy. We created a job that runs `/bin/date` and stores the output in `the-date.txt`. \n",
    "Now we need to run it. In order to do so, we need an *executor* that knows how to run jobs. We will use a simple fork/exec based executor named `local`. On a real cluster, we would use something like `SLURM` or `LSF`, but we are not doing this on a real cluster. However, I will note here that in most cases, simply changing `local` to the name of the scheduler used by the cluster would be sufficient to run the job through the cluster scheduler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psij import JobExecutor\n",
    "\n",
    "executor = JobExecutor.get_instance('local')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now tell the executor to run our job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executor.submit(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [submit()](https://exaworks.org/psij-python/#docs/.generated/psij.html/#psij.job_executor.JobExecutor.submit) method **starts** the job asynchronously.\n",
    "We would now like to see the result. However, before we can do so, we must ensure that the job has actually finished running. We can do so by [waiting](https://exaworks.org/psij-python/#docs/.generated/psij.html/#psij.job.Job.wait) for it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `wait()` method returns the [JobStatus](https://exaworks.org/psij-python/#docs/.generated/psij.html/#psij.JobStatus). Since nothing can possibly go wrong, we will assume that the job completed successfully and that there is no need to check the status to confirm it. Now, we can finally read the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('the-date.txt') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Jobs\n",
    "Our executor is stateless. That means that we can submit as many jobs as we want to it. That's in theory. In practice, computers have limited resources and there are only so many concurrent jobs that we can run, but hopefully we won't hit those limits today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = []\n",
    "for i in range(10):\n",
    "    job = Job(\n",
    "        JobSpec(\n",
    "            executable='/bin/echo', \n",
    "            arguments=['Hello from job %s' % i],\n",
    "            stdout_path=Path('hello-%s.txt' % i)\n",
    "        )\n",
    "    )\n",
    "    executor.submit(job)\n",
    "    jobs.append(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If these jobs weren't so short, they would now be running in parallel. In fact, why not start a longer job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_job = Job(JobSpec(executable='/bin/sleep', arguments=['600']))\n",
    "executor.submit(long_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to our previous jobs. In order to read their outputs, we must, again, ensure that they are done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    jobs[i].wait()\n",
    "    with open('hello-%s.txt' % i) as f:\n",
    "        print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about our long job?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(long_job.status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still running. The time shows the instant when the job switched to `ACTIVE` state. Moving on..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-process Jobs\n",
    "So far we've run multiple independent jobs. But what if we wanted to run multiple copies of one job, presumably on multiple compute nodes (this is a Docker container, but we can pretend)?\n",
    "We could tell PSI/J to do this using [ResourceSpecV1](https://exaworks.org/psij-python/#docs/.generated/psij.html/#psij.resource_spec.ResourceSpecV1). We also need to tell PSI/J to start our job a bit differently, so we'll make a short detour to talk about launchers.\n",
    "\n",
    "Once a job's resources are allocated, a typical job scheduler will launch our job on one of the allocated compute nodes. Then, we'd invoke something like `mpirun` or `srun`, etc. to start all the job copies on the allocated resources. By default, PSI/J uses a custom launcher named `single`, which simply starts a single copy of the job on the lead node of the job. If we wanted to see multiple copies of the job without any of the fancy features offered by `mpirun` or `srun`, we could use PSI/J's `multiple` launcher, which we will do below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psij import ResourceSpecV1\n",
    "\n",
    "mjob = Job(\n",
    "        JobSpec(\n",
    "            executable='/bin/date', \n",
    "            stdout_path=Path('multi-job-out.txt'),\n",
    "            resources=ResourceSpecV1(process_count=4),\n",
    "            launcher=\"multiple\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We informed PSI/J that we need four copies of our job. On a real scheduler, we could also request that these copies be distributed on multiple compute nodes, but, on this VM, we only have one such compute node, so we shouldn't bother."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executor.submit(mjob)\n",
    "mjob.wait()\n",
    "with open('multi-job-out.txt') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MPI Jobs\n",
    "\n",
    "The previous example ran a multi-process job, which has its use. It is more likely, however, to want to run an MPI job. Assuming that the system has some form of MPI installed, which this Docker container has, and which comes with some generic `mpirun` tool, we can instruct PSI/J to launch MPI jobs. And, as the previous sentence hints, it may be as simple as changing our launcher from `multiple` to `mpirun`, which it is.\n",
    "\n",
    "But before that, we need a simple MPI executable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat <<EOF >hello.c\n",
    "#include <stdio.h>\n",
    "#include <mpi.h>\n",
    "\n",
    "void main(int argc, char **argv) {\n",
    "    int rank;\n",
    "    MPI_Init(&argc, &argv);\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "    \n",
    "    printf(\"Hello from rank %d\\n\", rank);\n",
    "    \n",
    "    MPI_Finalize();\n",
    "}\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which we need to compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mpicc hello.c -o hello"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can construct our job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpi_job = Job(\n",
    "        JobSpec(\n",
    "            executable='hello', \n",
    "            stdout_path=Path('mpi-job-out.txt'),\n",
    "            resources=ResourceSpecV1(process_count=4),\n",
    "            launcher=\"mpirun\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and, as usual, wait for it and display the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executor.submit(mpi_job)\n",
    "mpi_job.wait()\n",
    "with open('mpi-job-out.txt') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the long running job?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(long_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soon, soon..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "\n",
    "Examples above are more or less synchronous, in that we use `wait()` to suspend the current thread until a job completes. In real life scenarios where scalability is needed, we would use callbacks. Let's implement a quick map/reduce workflow. We'll Monte Carlo calculate π using a map-reduce like algorithm.\n",
    "\n",
    "The basic idea is to generate some random points on a square that encloses one quadrant of a circle. \n",
    "\n",
    "<img src=\"./images/pi.png\" width=\"150\"/>\n",
    "\n",
    "Some points will fall outside the circle and some inside. As the number of points grows, the ratio of points inside the circle vs points inside the full square (total points) will be proportional to the ratio of their areas: \n",
    "\n",
    "N<sub>circle</sub> / N<sub>total</sub> ≈ A<sub>circle</sub> / A<sub>square</sub> = (πr<sup>2</sup> / 4) / r<sup>2</sup>\n",
    "\n",
    "Hence\n",
    "\n",
    "π = 4 N<sub>circle</sub> / N<sub>total</sub>\n",
    "\n",
    "We'll start with some boilerplate, the number of iterations, and the radius of the circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Lock\n",
    "from psij import JobState\n",
    "import math\n",
    "\n",
    "N = 100\n",
    "R = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we'll define a class that keeps track of our points and calculates π once we have all the points in, and we'll create an instance of it to hold actual results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Results:\n",
    "    def __init__(self):\n",
    "        self.n = 0\n",
    "        self.inside = 0\n",
    "        self._lock = Lock()\n",
    "        \n",
    "    def point_received(self, x, y):\n",
    "        with self._lock:\n",
    "            self.n += 1\n",
    "            if math.sqrt(x * x + y * y) < R:\n",
    "                self.inside += 1\n",
    "            if self.n == N:\n",
    "                print(\"π is %s\" % (float(self.inside) / self.n * 4))\n",
    "\n",
    "results = Results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we'll define a callback function that gets invoked every time a job changes status, and have it read the output and pass it to the `results` instance. The output will be in the form `x y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback(job, status):\n",
    "    if status.state == JobState.COMPLETED:\n",
    "        with open(job.spec.stdout_path) as f:\n",
    "            line = f.read().strip()\n",
    "            tokens = line.split()\n",
    "            results.point_received(int(tokens[0]), int(tokens[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike in previous cases, we now need to check the state of the job. That is because the full lifecycle of the job includes states such as `QUEUED` and `ACTIVE`, and the callback is invoked on all state changes.\n",
    "\n",
    "Finally, we can create and submit our jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(N):\n",
    "    job = Job(JobSpec('echo', '/bin/bash', \n",
    "                      ['-c', 'echo $((RANDOM%{})) $((RANDOM%{}))'.format(R, R)], \n",
    "                      stdout_path=Path('pi-x-y-%s.txt' % i)))\n",
    "    job.set_job_status_callback(callback)\n",
    "    executor.submit(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sure!\n",
    "Notice that the main thread is free as soon as the last job is submitted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's about it for this tutorial. Oh, the long running job should be done now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(long_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If not, we can stop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_job.cancel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, now we're really done. So it's clean up time. And you know what they say, if all you have is a hammer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/tutorials')\n",
    "cleanup_job = Job(\n",
    "    JobSpec(\n",
    "        executable='/bin/rm',\n",
    "        arguments=['-rf', workdir],\n",
    "        directory=Path('/tutorials/userdirs') # the job's working directory will be /tutorials/userdirs\n",
    "    )\n",
    ")\n",
    "executor.submit(cleanup_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thank you!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "76009bf859c7381f9309fe432e50ba00bc4a43c07b3a3292e8eda4f7573404cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
